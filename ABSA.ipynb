{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdefd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade transformers\n",
    "# %pip install --upgrade torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537ea15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\SUJAL' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.3 in c:\\users\\sujal das\\anaconda3\\envs\\mca\\lib\\site-packages (3.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: hf_xet in c:\\users\\sujal das\\anaconda3\\envs\\mca\\lib\\site-packages (1.1.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\sujal das\\anaconda3\\envs\\mca\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\sujal das\\anaconda3\\envs\\mca\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\sujal das\\anaconda3\\envs\\mca\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (4.14.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sujal das\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda activate mca\n",
    "%pip install protobuf==3.20.3\n",
    "%pip install hf_xet\n",
    "%pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754512e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\sujal das\\anaconda3\\envs\\mca\\lib\\site-packages (1.2.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4391230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e97eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: GPU\n",
      "üîÑ Loading ABSA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUJAL DAS\\anaconda3\\envs\\mca\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running ABSA on comments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ABSA:   2%|‚ñè         | 10/450 [00:23<17:59,  2.45s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing ABSA: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 450/450 [17:54<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ABSA completed. Results saved in absa_results.csv\n",
      "\n",
      "üìä Sentiment Distribution:\n",
      "Out of 28756 comments:\n",
      "Positive: 10152\n",
      "Negative: 8663\n",
      "Neutral: 9941\n",
      "\n",
      "‚ö†Ô∏è Groq API Error: 400 Client Error: Bad Request for url: https://api.groq.com/openai/v1/chat/completions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Load Dataset\n",
    "# ------------------------------\n",
    "df = pd.read_csv(\"combined_comments.csv\")\n",
    "df['Comment'] = df['Comment'].fillna('')\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Check for GPU\n",
    "# ------------------------------\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Device set to: {'GPU' if device==0 else 'CPU'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Load ABSA Model\n",
    "# ------------------------------\n",
    "print(\"üîÑ Loading ABSA model...\")\n",
    "absa = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"yangheng/deberta-v3-base-absa-v1.1\",\n",
    "    tokenizer=\"yangheng/deberta-v3-base-absa-v1.1\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Run ABSA in batches for speed\n",
    "# ------------------------------\n",
    "print(\"üîÑ Running ABSA on comments...\")\n",
    "\n",
    "batch_size = 64  # increase if GPU memory allows\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size), desc=\"Processing ABSA\"):\n",
    "    batch_texts = df['Comment'].iloc[i:i+batch_size].tolist()\n",
    "    try:\n",
    "        batch_output = absa(batch_texts, truncation=True, max_length=512)\n",
    "        results.extend([o['label'] for o in batch_output])\n",
    "    except Exception as e:\n",
    "        results.extend([\"Error\"] * len(batch_texts))\n",
    "\n",
    "df['ABSA_Sentiment'] = results\n",
    "\n",
    "# Save ABSA results\n",
    "df.to_csv(\"absa_results.csv\", index=False)\n",
    "print(\"‚úÖ ABSA completed. Results saved in absa_results.csv\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Prepare Summary Stats\n",
    "# ------------------------------\n",
    "positive_count = sum(df['ABSA_Sentiment'] == \"Positive\")\n",
    "negative_count = sum(df['ABSA_Sentiment'] == \"Negative\")\n",
    "neutral_count = sum(df['ABSA_Sentiment'] == \"Neutral\")\n",
    "\n",
    "summary_input = (\n",
    "    f\"Out of {len(df)} comments:\\n\"\n",
    "    f\"Positive: {positive_count}\\n\"\n",
    "    f\"Negative: {negative_count}\\n\"\n",
    "    f\"Neutral: {neutral_count}\\n\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Sentiment Distribution:\")\n",
    "print(summary_input)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Send to Groq API for Summarization\n",
    "# ------------------------------\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"mixtral-8x7b-32768\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that summarizes sentiment analysis results.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize these sentiment counts in a short paragraph:\\n{summary_input}\"}\n",
    "    ],\n",
    "    \"temperature\": 0.3,\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    final_summary = result['choices'][0]['message']['content']\n",
    "    print(\"\\nüìù Groq Summary:\")\n",
    "    print(final_summary)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Groq API Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bdcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
